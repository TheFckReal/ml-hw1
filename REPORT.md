# Отчет по Домашнему заданию №1 (pro). Часть 1

## Что было сделано

В рамках работы была проведена комплексная работа по анализу данных и построению моделей регрессии для предсказания стоимости автомобилей. Основные этапы работы:

1.  **Разведочный анализ данных (EDA):**
    -   Загрузка и очистка данных: обработка дубликатов, приведение типов для столбцов `mileage`, `engine`, `max_power`, парсинг столбца `torque`.
    -   Заполнение пропусков медианными значениями.
    -   Визуализация распределений и зависимостей (pairplot, heatmap), анализ корреляций (Пирсон, Спирмен, Phik).

2.  **Базовое моделирование (только вещественные признаки):**
    -   Обучение **LinearRegression** на числовых признаках.
    -   Применение стандартизации (`StandardScaler`) для интерпретации весов и масштабирования.
    -   Эксперименты с регуляризацией: **Lasso**, **Ridge**, **ElasticNet** с подбором гиперпараметров через `GridSearchCV`.
    -   Реализация и тестирование кастомной **L0-регуляризации** (жадный отбор признаков через удаление признаков и обучение модели, сформирован собственный параметр регуляризации).

3.  **Работа с категориальными признаками:**
    -   Кодирование категориальных признаков (включая `seats`) методом **OneHotEncoding** c дропом категории.
    -   Обучение **Ridge** регрессии на расширенном наборе данных.

4.  **Feature Engineering:**
    -   Генерация новых признаков: `brand` (из названия), `age` (возраст авто), `power_per_liter` (мощность на литр), `km_per_year` (пробег в год).
    -   Добавление полиномиальных признаков (2-ой степени).
    -   **Логарифмирование целевой переменной** (`selling_price`) для  уменьшения проблемы масштаба и избавления от "хвоста".
    -   Создание пайплайна обработки данных.

5.  **Оценка бизнес-метрик:**
    -   Реализация метрики "доля прогнозов с ошибкой не более 10%".
    -   Реализация кастомной метрики с асимметричным штрафом (недопрогноз штрафуется сильнее перепрогноза).

6. **Дополнительные требования:**
    -   Все веса моделей и пост-обработчиков (scaler, OHE, ...) сохранены по пути `./models/`

## С какими результатами

Качество моделей оценивалось по метрикам $R^2$ и MSE.

*   **Базовая линейная регрессия (числовые признаки):** $R^2 \approx 0.597$. Модель объясняла около 60% дисперсии, что является средним результатом.
*   **Регуляризация (Lasso, ElasticNet):** Существенного прироста качества на числовых данных не дала ($R^2 \approx 0.59 - 0.60$). L0-регуляризация позволила сократить число признаков до 5 без потери качества.
*   **Ridge на категориальных данных:** $R^2 \approx 0.783$. Значительное улучшение качества.
*   **Финальная модель (Ridge + Feature Eng + Log Target):** **$R^2 \approx 0.935$**, MSE $\approx 3.7 \times 10^{10}$. Это наилучший результат.
*   **Бизнес-метрика (точность 10%):** Лучшая модель показала результат **0.367** (36.7% предсказаний попадают в 10% интервал ошибки).

## Что дало наибольший буст в качестве

1.  **Логарифмирование целевой переменной:** Это действие (вместе с обогащением пространства признаков) дало финальный скачок метрики $R^2$ с ~0.78 до ~0.935. Распределение цен имело "тяжелый хвост", и логарифмирование позволило линейной модели намного лучше описывать зависимость.
2.  **Добавление категориальных признаков и наличие полиномиальных фичей:** Использование `OneHotEncoder` для текстовых полей (особенно модели авто) и произведение признаков вплоть до 2 степени (в том числе и квадрат признака) дало прирост с $R^2 \approx 0.60$ до $R^2 \approx 0.78$. Информативность названия автомобиля оказалась во многом доминирующей по важности.

## Что сделать не вышло и почему

*   **Эффективный отбор признаков через Lasso (L1):** На исходном наборе вещественных признаков Lasso-регрессия даже с подбором параметров не занулила коэффициенты, что, вероятно, говорит о важности всех доступных числовых признаков для базовой модели. На более высоких коэффициентах регуляризации (>1000) модель становилась сильно хуже, хоть и пыталась занулить веса.

P.S. Красивое оформление и помощь с текстом были произведены Gemini 3 Pro